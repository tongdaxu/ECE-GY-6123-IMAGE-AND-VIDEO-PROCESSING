{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTER ASSIGNMENT 04\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net for image segmentation\n",
    "\n",
    "In class, we talked about U-net for image segmentation. This assignment is intended to \n",
    "- help you better understand the concept of U-net for image segmentation \n",
    "- help you get started with designing networks in pytorch including loading data, network design, loss function, training and testing.\n",
    "\n",
    "For this assignment, you will attempt to segment car images, which is a challenge hosted on [Kaggle](https://www.kaggle.com/c/carvana-image-masking-challenge/data).  The original data is available on the Kaggle website. We have extracted a small part of the dataset and uploaded it to the following link \n",
    "\n",
    "\n",
    "https://www.dropbox.com/sh/e8j991bsd269fcq/AACARtYIoYnQaydahUlo22NFa?dl=0\n",
    "\n",
    "You should create a folder 'data/' in the current folder.\n",
    "\n",
    "Then download train, train_mask, test dataset from the above link and extract them to 'data/'.\n",
    "\n",
    "Or you can download the whole dataset from [Kaggle website](https://www.kaggle.com/c/carvana-image-masking-challenge/data).\n",
    "\n",
    "Let's first take a look at the images in the training dataset\n",
    "<img src=\"00087a6bd4dc_01.jpg\" width=\"200\" height=\"200\" />\n",
    " \n",
    " Each image in the training dataset has a corresponding mask\n",
    "<img src=\"00087a6bd4dc_01_mask.gif\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "You should \n",
    " -  Implement the U-net of the following architechure.\n",
    " ![U-net](U-net_architecture.png)\n",
    " -  Write function dice_coeff(input, target) for evaluation\n",
    " -  Load training dataset and testing dataset.\n",
    " Notice that you should rescale the images to a smaller size. Otherwise it's impossible to train on cpu.\n",
    " -  Train your network for a few epochs.\n",
    " -  Test your model by feeding in a new image in testing dataset. Plot your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# Need extra import !\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from skimage import transform\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ TODO 1 ] First define following layers to be used later\n",
    "- **Conv2d + BatchNorm2d + ReLu ** as **single conv2d layer** ,\n",
    "- **Maxpool2d + single conv2d layer ** as **down layer**,\n",
    "- **Upsample + single conv2d layer ** as **up layer** ,\n",
    "-  **Conv2d ** as **outconv layer** \n",
    "\n",
    "You can check out the documentation in this link to understand how to use the methods called in the provided template:\n",
    "\n",
    " https://pytorch.org/docs/stable/nn.html\n",
    " \n",
    "  ![single_conv](single_conv_layer.png)\n",
    "  ![down_layer](down_layer.png)\n",
    "  ![up_layer](Up_layer.png)\n",
    "  ![outconv_layer](outconv_layer.png)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# DEFINE SINGLE_CONV CLASS\n",
    "class single_conv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(single_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True) # Save memory\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# DEFINE DOWN CLASS\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.down = nn.MaxPool2d(kernel_size=2, stride=2) # use nn.MaxPool2d( )\n",
    "        self.conv = single_conv(in_ch, out_ch) # use previously defined single_cov\n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# DEFINE UP CLASS\n",
    "# Note that this class will not only upsample x1, but also concatenate up-sampled x1 with x2 to generate the final output\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up, self).__init__()       \n",
    "        self.up = nn.Upsample(scale_factor=2) # use nn.Upsample( )\n",
    "        self.conv = single_conv(in_ch, out_ch) # use previously defined single_cov\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # This part is tricky, so we provide it for you\n",
    "        # First we upsample x1\n",
    "        x1 = self.up(x1)\n",
    "            \n",
    "        # Notice that x2 and x1 may not have the same spatial size. \n",
    "        # This is because when you downsample old_x2(say 25 by 25), you will get x1(12 by 12)   \n",
    "        # Then you perform upsample to x1, you will get new_x1(24 by 24)\n",
    "        # You should pad a new row and column so that new_x1 and x2 have the same size.\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        \n",
    "        # Now we concatenat x2 channels with x1 channels\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# DEFINE OUTCONV CLASS\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3) # Use nn.Conv2D( ) since we do not need to do batch norm and relu at this layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Build your network with predefined classes: single_conv, up, down, outconv\n",
    "# The number of input and output channels should follow the U-Net Structure shown above.\n",
    "import torch.nn.functional as F\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = single_conv(n_channels, 16) # conv2d +  batchnorm + relu\n",
    "        self.down1 = down(16, 32)         # maxpool2d + conv2d + batchnorm + relu\n",
    "        self.down2 = down(32, 32)         # maxpool2d + conv2d + batchnorm + relu\n",
    "\n",
    "        self.up1 = up(64, 16)             # upsample + pad + conv2d + batchnorm + relu\n",
    "        self.up2 = up(32, 16)             # upsample + pad + conv2d + batchnorm + relu\n",
    "\n",
    "        self.outc = outconv(16, 1)        # conv2d\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "\n",
    "        x = self.up1(x3, x2)\n",
    "        x = self.up2(x, x1)\n",
    "\n",
    "        x = self.outc(x)\n",
    "        return F.sigmoid(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ TODO 2 ] Define evaulation function:\n",
    "Based on what we have learnt in class, Dice coefficient is defined as \n",
    "![dice.png](dice.png)\n",
    "For the case of evaluating a Dice coefficient on predicted segmentation masks, we can approximate intersection of A and B as the element-wise multiplication between the prediction and target mask, and then sum the resulting matrix.\n",
    "\n",
    "In order to quantify the area of A union B, some researchers use the simple sum whereas other researchers prefer to use the squared sum for this calculation. You can use either way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# define dice coefficient \n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        eps = 0.0001 # in case union = 0\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Calculate intersection and union. \n",
    "        # You can convert the input image into a vector with input.contiguous().view(-1)\n",
    "        # Then use torch.dot(A, B) to calculate the intersection.\n",
    "        # Use torch.sum(A) to get the sum.\n",
    "        self.inter = torch.sum(input*target) # Instruction looks strange\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "        # Calculate DICE \n",
    "        d = self.inter/self.union\n",
    "        return d\n",
    "\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# Calculate dice coefficients for batches\n",
    "def dice_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(input, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "    for i, c in enumerate(zip(input, target)):\n",
    "        s = s + DiceCoeff.forward(c[0], c[1]) \n",
    "    s = s / (i + 1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks\n",
    "\n",
    "Load training imagse, normalize and resize them into smaller size so that you can perform training using a CPU. Split them into training and validation. Validation percent of 0.05 means 5% of training dataset is used as validation. In order to avoid repeated data preprocessing, we use the pickle tool to save the processed data.\n",
    "\n",
    "This part has been done for you. But please read through so that you learn the general processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to split the whole train dataset into train and validation, and match the train image path with the \n",
    "# corresponding label path\n",
    "def split_train_val(image_paths, mask_paths, train_size):\n",
    "    img_paths_dic = {}\n",
    "    mask_paths_dic = {}\n",
    "    len_data = len(image_paths)\n",
    "    print('total len:', len_data)\n",
    "    for i in range(len(image_paths)):\n",
    "        img_paths_dic[os.path.basename(image_paths[i])[:-4]] = image_paths[i]\n",
    "\n",
    "    for i in range(len(mask_paths)):\n",
    "        mask_paths_dic[os.path.basename(mask_paths[i])[:-9]] = mask_paths[i]\n",
    "        \n",
    "    img_mask_list = []\n",
    "    for key in img_paths_dic:\n",
    "        img_mask_list.append((img_paths_dic[key], mask_paths_dic[key]))\n",
    "        \n",
    "    train_img_mask_paths = img_mask_list[:int(len_data*train_size)] \n",
    "    val_img_mask_paths = img_mask_list[int(len_data*train_size):]\n",
    "    return train_img_mask_paths, val_img_mask_paths\n",
    "\n",
    "# read in the image and label pair, and then resize them from 1280*1918 to 80*100 by consideration of \n",
    "# your computer memory limitation\n",
    "def preprocess_image(image_mask_paths):\n",
    "    img_mask_list = []\n",
    "    new_h, new_w = 80, 100\n",
    "    \n",
    "    for i in tqdm(range(len(image_mask_paths))):\n",
    "        img = np.array(Image.open(image_mask_paths[i][0]), np.float32) / 255.0 \n",
    "        mask = np.array(Image.open(image_mask_paths[i][1]), np.uint8)\n",
    "        \n",
    "        img_resize = transform.resize(img, (new_h, new_w), mode='constant', anti_aliasing=True, preserve_range=True)\n",
    "        mask_resize = np.uint8(transform.resize(mask, (new_h, new_w), mode='constant', anti_aliasing=True, preserve_range=True))\n",
    "               \n",
    "        img_mask_list.append((img_resize, mask_resize))\n",
    "    return img_mask_list\n",
    "\n",
    "# save the data into pickle file and you can just reload this file, which can help you avoid reading the image\n",
    "# file again in the future, since reading in image file from hard drive would take quite a long time\n",
    "def pickle_store(file_name,save_data):\n",
    "    fileObj = open(file_name,'wb')\n",
    "    pickle.dump(save_data,fileObj)\n",
    "    fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape: (1280, 1918, 3)\n",
      "orginal mask shape: (1280, 1918)\n",
      "total len: 5088\n",
      "train len: 4833, val len: 255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get all the image and mask path and number of images\n",
    "image_paths = glob.glob(\"data/train/*.jpg\")\n",
    "mask_paths = glob.glob(\"data/train_masks/*.gif\")\n",
    "\n",
    "# split these path using a certain percentage\n",
    "train_size = 0.95\n",
    "print('original image shape: {}'.format(np.array(Image.open(image_paths[0])).shape))\n",
    "print('orginal mask shape: {}'.format(np.array(Image.open(mask_paths[0])).shape))\n",
    "\n",
    "train_img_mask_paths, val_img_mask_paths = split_train_val(image_paths, mask_paths, train_size)\n",
    "\n",
    "print('train len: {}, val len: {}'.format(len(train_img_mask_paths),len(val_img_mask_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 4833\n"
     ]
    }
   ],
   "source": [
    "train_img_masks_save_path = './data/train_img_masks.pickle'\n",
    "if os.path.exists(train_img_masks_save_path):\n",
    "    with open(train_img_masks_save_path,'rb') as f:\n",
    "        train_img_masks = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    train_img_masks = preprocess_image(train_img_mask_paths)\n",
    "    pickle_store(train_img_masks_save_path,train_img_masks)\n",
    "print('train len: {}'.format(len(train_img_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val len: 255\n"
     ]
    }
   ],
   "source": [
    "val_img_masks_save_path = './data/val_img_masks.pickle'\n",
    "if os.path.exists(val_img_masks_save_path):\n",
    "    with open(val_img_masks_save_path,'rb') as f:\n",
    "        val_img_masks = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    val_img_masks = preprocess_image(val_img_mask_paths)\n",
    "    pickle_store(val_img_masks_save_path,val_img_masks)\n",
    "print('val len: {}'.format(len(val_img_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Let us display some of the images to make sure the data loading and processing is correct.\n",
    "### the original size of the image is: 1280*1918, but we resize the image to 80*100 for \n",
    "### training the segmentation network\n",
    "img_num = 5\n",
    "plt.imshow(train_img_masks[img_num][0])\n",
    "plt.title(\"sample image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_img_masks[img_num][1], cmap='gray')\n",
    "plt.title(\"ground true segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets in the format that you can later use Torch  \"DataLoader\" during training and define  data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define transform classes for  data augmentation\n",
    "class Flip(object):\n",
    "    \"\"\"\n",
    "    Flip the image left or right for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    def __init__(self,ori_probability=0.60):\n",
    "        self.ori_probability = ori_probability\n",
    " \n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['img'], sample['label']\n",
    "            img_flip = img[:,:,::-1]\n",
    "            label_flip = label[:,::-1]\n",
    "            \n",
    "            return {'img': img_flip, 'label': label_flip}\n",
    "        \n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.DoubleTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.DoubleTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None):   # initial logic happens like transform\n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_masks[index][0] # H, W, C\n",
    "        mask = self.image_masks[index][1]\n",
    "        \n",
    "        image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "        \n",
    "        sample = {'img': image, 'label': mask}\n",
    "        \n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "            \n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_img_masks, transforms=transforms.Compose([Flip(),ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([Flip(),ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ TODO 3 ] Start training your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# This function is used to evaluate the network after each epoch of training\n",
    "# Input: network and validation dataset\n",
    "# Output: average dice_coeff\n",
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img']\n",
    "        B = img.shape[0]\n",
    "        true_mask = np.array(b['label'].view(B,-1))\n",
    "        ################################################ [TODO] ################################################### \n",
    "        # Feed in the image to get predicted mask\n",
    "        mask_pred = net(img)\n",
    "        # For all pixels in predicted mask, set them to 1 if larger than 0.5. Otherwise set them to 0\n",
    "        mask_pred = torch.round(mask_pred)\n",
    "        # calculate dice_coeff()\n",
    "        # note that you should add all the dice_coeff in validation/testing dataset together \n",
    "        # call dice_coeff() here\n",
    "        tot += dice_coeff(mask_pred, true_mask)\n",
    "        # Return average dice_coeff()\n",
    "    return tot / (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Create a UNET object. Input channels = 3, output channels = 1\n",
    "net = UNet(n_channels=3, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/4.\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c36d00664615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;31m################################################ [TODO] ###################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# Get images and masks from each batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\cs231\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Specify number of epochs, image scale factor, batch size and learning rate\n",
    "epochs = 4 # i.e, 4\n",
    "batch_size = 4 # i.e, 16\n",
    "lr = 1e-2        # i.e, 0.01\n",
    "N_train = len(train_img_masks)\n",
    "model_save_path = './model/'  # directory to same the model after each epoch. \n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# Define an optimizer for your model.\n",
    "# Pytorch has built-in package called optim. Most commonly used methods are already supported.\n",
    "# Here we use stochastic gradient descent to optimize\n",
    "# For usage of SGD, you can read https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html\n",
    "# Also you can use ADAM as the optimizer\n",
    "# For usage of ADAM, you can read https://www.programcreek.com/python/example/92667/torch.optim.Adam\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "#suggested parameter settings: momentum=0.9, weight_decay=0.0005\n",
    "\n",
    "#OR optimizer = optim.Adam(...)\n",
    "\n",
    "\n",
    "# The loss function we use is binary cross entropy: nn.BCELoss()\n",
    "criterion = nn.BCELoss()\n",
    "# note that although we want to use DICE for evaluation, we use BCELoss for training in this example\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, b in enumerate(train_loader):\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Get images and masks from each batch\n",
    "        imgs = b['img']\n",
    "        true_mask = b['label']\n",
    "\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Feed your images into the network\n",
    "        masks_pred = net(imgs)\n",
    "        # Flatten the predicted masks and true masks. For example, A_flat = A.view(-1)\n",
    "        masks_probs_flat = masks_pred.view(b,-1)\n",
    "        true_masks_flat = true_mask.view(b,-1)\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together \n",
    "        loss = criterion(masks_probs_flat, true_masks_flat)\n",
    "        epoch_loss += loss.item() # .item() stops gradient\n",
    "\n",
    "        print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. \n",
    "        # Its important to call this before loss.backward(), otherwise youll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. \n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        # x.grad += dloss/dx\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad. \n",
    "        # x += -lr * x.grad\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "    ################################################ [TODO] ###################################################\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    val_dice = eval_net(net, val_dataset)\n",
    "    print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    # Save the model after each epoch\n",
    "    if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Car_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Car_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ TODO 4 ] load one image from testing dataset and plot output mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Define a function for prediction/testing\n",
    "def predict_img(net,full_img,out_threshold=0.5):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "    \n",
    "    # convert from Height*Width*Channel TO Channel*Height*Width\n",
    "    full_img = ...\n",
    "    # convert numpy array to torch tensor \n",
    "    X_img = ...\n",
    "    with torch.no_grad():\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # predict the masks \n",
    "        output_img = ...\n",
    "        out_probs = output_img.squeeze(0)\n",
    "        # threshold the probability to generate mask: mask=1 if prob > out_threshold, set mask to uint8 \n",
    "        out_mask_np = ...\n",
    "\n",
    "    # For all pixels in predicted mask, set them to 1 if larger than out_threshold. Otherwise set them to 0\n",
    "    return out_mask_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Load an image from testing dataset\n",
    "test_img = ...\n",
    "# Normalize to [0,1]\n",
    "test_img = ...\n",
    "# Rescale the size of the image to 80*100\n",
    "img_resize = ...\n",
    "################################################ [TODO] ###################################################\n",
    "# Predict the mask\n",
    "mask = predict_img(net=net,\n",
    "                    img=test_img,\n",
    "                    out_threshold=...)\n",
    "# Rescale the mask back to original image size\n",
    "mask_full = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot original image and mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original images and masks\n",
    "...\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IVP",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
